for (n in names(init)) init[[n]]=unlist(init[[n]])
# set the seed so we can use the same seed for the alternative model
set.seed(1)
null_gradient_function=function(g) sampler$grad_log_prob(g,T)
null_likelihood=function(g) sampler$log_prob(g,T,F)
v_null=svem(null_gradient_function, to_optim, init, plot.elbo = F, iterations = maxit, samples_for_elbo = 0, log_prob = null_likelihood)
# data for alternative (full) model
dat_full=list(N=length(ys), P=ncol(xFull), K=max(z), ys=ys,ns=ns,x=xFull, z=z, concShape=concShape, concRate=concRate)
# specify which parameters to optimize
sampler2=get_sampler(BETABINOMIAL_GLMM, dat_full)
sk_full=get_skeleton(sampler2)
sk_full$conc=T
sk_full$logrev=T
sk_full$beta[]=T
sk_full$u[]=F
to_optim=as.logical(unlist(sk_full))
# initialization choices: initializing from null fit seems best
if (0) {
o_init=o$par
o_init$beta=c(o_init$beta, rep(0,df))
o=optimizing(STANGLM_MV, dat_full, as_vector=F)
init=list(m=get_skeleton(sampler2), s=get_skeleton(sampler2))
init$m$conc=log(o$par$conc)
init$m$beta=o$par$beta
for (n in names(init$s)) init$s[[n]][]=1
} else {
init=list( m=rstan:::rstan_relist(v_null$m, sk),
s=rstan:::rstan_relist(v_null$s, sk) )
init$m$beta=c(init$m$beta, rep(0,df))
init$s$beta=c(init$s$beta, rep(1,df)) # optimized anyway so this value will be ignored
}
init=list(m=unlist(init$m),s=unlist(init$s))
# fit alternative model
set.seed(1)
v_full=svem(function(g) sampler2$grad_log_prob(g,T), to_optim, init=init, plot.elbo = F, iterations = maxit, samples_for_elbo = 0, function(g) sampler2$log_prob(g,T,F))
# using the same random draws to estimate the deviance is more efficient
#nintegrate=sum(!to_optim)
#nsamp=2000
#loglr=c( mean(sapply(1:nsamp, function(g) {
#  x=rnorm(nintegrate)
#  v_full$elbo_func( x ) - v_null$elbo_func( x ) })),
loglr=mean(v_full$elbo_progress[maxit/2:maxit] - v_null$elbo_progress[maxit/2:maxit])
list(loglr=loglr, df=df, lrtp=pchisq( 2.0*loglr, lower.tail = F , df=df ) )
}
testbbglmm=function(seed=1) {
set.seed(seed)
nsamp=50
ns=rpois(nsamp * 2,lambda=10)
ys=rbinom(nsamp * 2,ns,logistic(.3+.3*rnorm(nsamp)))
xNull=cbind(numeric(nsamp*2)+1)
xFull=cbind(xNull,c(rep(0,nsamp),rep(1,nsamp)))
z=rep(1:nsamp,2)
c(betaBinomialGLMM(ys,ns,xFull,xNull,z)$lrtp, betaBinomialGLM(ys,ns,xFull,xNull)$lrtp[1])
}
a=foreach(i=1:100) %dopar% { testbbglmm(i) }
pv=do.call(rbind,a)
qplot(pv[,2],pv[,1]) + geom_abline(intercept=0,slope=1) + xlab("GLM -log10(p)") + ylab("GLMM -log10(p)") + theme_bw(base_size=16)
maxit/2:maxit
maxit=10
maxit/2:maxit
betaBinomialGLMM=function(ys,ns,xFull,xNull,z,concShape=1.0001,concRate=1e-4,maxit=10000,...) {
# check first ncol(xNull) columns of xFull and xNull match
stopifnot(all(xNull==xFull[,1:ncol(xNull)]))
# degress of freedom
df=ncol(xFull)-ncol(xNull)
# data for the null model
dat=list(N=length(ys), P=ncol(xNull), K=max(z), ys=ys,ns=ns,x=xNull,z=z, concShape=concShape, concRate=concRate)
# get stan_fit object so we can call sampler$grad_log_prob for the gradient
sampler=get_sampler(BETABINOMIAL_GLMM, dat)
# specific which parameters to optimize (rather than integrate over)
sk=get_skeleton(sampler)
sk$conc=T
sk$logrev=T
sk$beta[]=T
sk$u[]=F
to_optim=as.logical(unlist(sk))
# we initialize using the model fit without the random effects
o=optimizing(BETABINOMIAL_GLM, dat, as_vector=F)
init=list(m=get_skeleton(sampler), s=get_skeleton(sampler))
init$m$conc=log(o$par$conc)
init$m$beta=o$par$beta
for (n in names(init$s)) init$s[[n]][]=1 # set all standard deviations to 1 initially
for (n in names(init)) init[[n]]=unlist(init[[n]])
# set the seed so we can use the same seed for the alternative model
set.seed(1)
null_gradient_function=function(g) sampler$grad_log_prob(g,T)
null_likelihood=function(g) sampler$log_prob(g,T,F)
v_null=svem(null_gradient_function, to_optim, init, plot.elbo = F, iterations = maxit, samples_for_elbo = 0, log_prob = null_likelihood)
# data for alternative (full) model
dat_full=list(N=length(ys), P=ncol(xFull), K=max(z), ys=ys,ns=ns,x=xFull, z=z, concShape=concShape, concRate=concRate)
# specify which parameters to optimize
sampler2=get_sampler(BETABINOMIAL_GLMM, dat_full)
sk_full=get_skeleton(sampler2)
sk_full$conc=T
sk_full$logrev=T
sk_full$beta[]=T
sk_full$u[]=F
to_optim=as.logical(unlist(sk_full))
# initialization choices: initializing from null fit seems best
if (0) {
o_init=o$par
o_init$beta=c(o_init$beta, rep(0,df))
o=optimizing(STANGLM_MV, dat_full, as_vector=F)
init=list(m=get_skeleton(sampler2), s=get_skeleton(sampler2))
init$m$conc=log(o$par$conc)
init$m$beta=o$par$beta
for (n in names(init$s)) init$s[[n]][]=1
} else {
init=list( m=rstan:::rstan_relist(v_null$m, sk),
s=rstan:::rstan_relist(v_null$s, sk) )
init$m$beta=c(init$m$beta, rep(0,df))
init$s$beta=c(init$s$beta, rep(1,df)) # optimized anyway so this value will be ignored
}
init=list(m=unlist(init$m),s=unlist(init$s))
# fit alternative model
set.seed(1)
v_full=svem(function(g) sampler2$grad_log_prob(g,T), to_optim, init=init, plot.elbo = F, iterations = maxit, samples_for_elbo = 0, function(g) sampler2$log_prob(g,T,F))
# using the same random draws to estimate the deviance is more efficient
#nintegrate=sum(!to_optim)
#nsamp=2000
#loglr=c( mean(sapply(1:nsamp, function(g) {
#  x=rnorm(nintegrate)
#  v_full$elbo_func( x ) - v_null$elbo_func( x ) })),
loglr=mean(v_full$elbo_progress[(maxit/2):maxit] - v_null$elbo_progress[(maxit/2):maxit])
list(loglr=loglr, df=df, lrtp=pchisq( 2.0*loglr, lower.tail = F , df=df ) )
}
testbbglmm=function(seed=1) {
set.seed(seed)
nsamp=50
ns=rpois(nsamp * 2,lambda=10)
ys=rbinom(nsamp * 2,ns,logistic(.3+.3*rnorm(nsamp)))
xNull=cbind(numeric(nsamp*2)+1)
xFull=cbind(xNull,c(rep(0,nsamp),rep(1,nsamp)))
z=rep(1:nsamp,2)
c(betaBinomialGLMM(ys,ns,xFull,xNull,z)$lrtp, betaBinomialGLM(ys,ns,xFull,xNull)$lrtp[1])
}
a=foreach(i=1:100) %dopar% { testbbglmm(i) }
pv=do.call(rbind,a)
qplot(pv[,2],pv[,1]) + geom_abline(intercept=0,slope=1) + xlab("GLM -log10(p)") + ylab("GLMM -log10(p)") + theme_bw(base_size=16)
# check first ncol(xNull) columns of xFull and xNull match
stopifnot(all(xNull==xFull[,1:ncol(xNull)]))
# degress of freedom
df=ncol(xFull)-ncol(xNull)
# data for the null model
dat=list(N=length(ys), P=ncol(xNull), K=max(z), ys=ys,ns=ns,x=xNull,z=z, concShape=concShape, concRate=concRate)
# get stan_fit object so we can call sampler$grad_log_prob for the gradient
sampler=get_sampler(BETABINOMIAL_GLMM, dat)
# specific which parameters to optimize (rather than integrate over)
sk=get_skeleton(sampler)
sk$conc=T
sk$logrev=T
sk$beta[]=T
sk$u[]=F
to_optim=as.logical(unlist(sk))
# we initialize using the model fit without the random effects
o=optimizing(BETABINOMIAL_GLM, dat, as_vector=F)
init=list(m=get_skeleton(sampler), s=get_skeleton(sampler))
init$m$conc=log(o$par$conc)
init$m$beta=o$par$beta
for (n in names(init$s)) init$s[[n]][]=1 # set all standard deviations to 1 initially
for (n in names(init)) init[[n]]=unlist(init[[n]])
# set the seed so we can use the same seed for the alternative model
set.seed(1)
null_gradient_function=function(g) sampler$grad_log_prob(g,T)
null_likelihood=function(g) sampler$log_prob(g,T,F)
v_null=svem(null_gradient_function, to_optim, init, plot.elbo = F, iterations = iterations, samples_for_elbo = 0, log_prob = null_likelihood)
# data for alternative (full) model
dat_full=list(N=length(ys), P=ncol(xFull), K=max(z), ys=ys,ns=ns,x=xFull, z=z, concShape=concShape, concRate=concRate)
# specify which parameters to optimize
sampler2=get_sampler(BETABINOMIAL_GLMM, dat_full)
sk_full=get_skeleton(sampler2)
sk_full$conc=T
sk_full$logrev=T
sk_full$beta[]=T
sk_full$u[]=F
to_optim=as.logical(unlist(sk_full))
# initialization choices: initializing from null fit seems best
if (0) {
o_init=o$par
o_init$beta=c(o_init$beta, rep(0,df))
o=optimizing(STANGLM_MV, dat_full, as_vector=F)
init=list(m=get_skeleton(sampler2), s=get_skeleton(sampler2))
init$m$conc=log(o$par$conc)
init$m$beta=o$par$beta
for (n in names(init$s)) init$s[[n]][]=1
} else {
init=list( m=rstan:::rstan_relist(v_null$m, sk),
s=rstan:::rstan_relist(v_null$s, sk) )
init$m$beta=c(init$m$beta, rep(0,df))
init$s$beta=c(init$s$beta, rep(1,df)) # optimized anyway so this value will be ignored
}
init=list(m=unlist(init$m),s=unlist(init$s))
# fit alternative model
set.seed(1)
v_full=svem(function(g) sampler2$grad_log_prob(g,T), to_optim, init=init, plot.elbo = F, iterations = iterations, samples_for_elbo = 0, function(g) sampler2$log_prob(g,T,F))
# using the same random draws to estimate the deviance is more efficient
nintegrate=sum(!to_optim)
loglr=mean(sapply(1:elbo_samples, function(g) {
x=rnorm(nintegrate)
v_full$elbo_func( x ) - v_null$elbo_func( x ) }))
#loglr=mean(v_full$elbo_progress[(maxit/2):maxit] - v_null$elbo_progress[(maxit/2):maxit])
list(loglr=loglr, df=df, lrtp=pchisq( 2.0*loglr, lower.tail = F , df=df ) )
iterations=5000
elbo_samples=3000
stopifnot(all(xNull==xFull[,1:ncol(xNull)]))
# degress of freedom
df=ncol(xFull)-ncol(xNull)
# data for the null model
dat=list(N=length(ys), P=ncol(xNull), K=max(z), ys=ys,ns=ns,x=xNull,z=z, concShape=concShape, concRate=concRate)
# get stan_fit object so we can call sampler$grad_log_prob for the gradient
sampler=get_sampler(BETABINOMIAL_GLMM, dat)
# specific which parameters to optimize (rather than integrate over)
sk=get_skeleton(sampler)
sk$conc=T
sk$logrev=T
sk$beta[]=T
sk$u[]=F
to_optim=as.logical(unlist(sk))
# we initialize using the model fit without the random effects
o=optimizing(BETABINOMIAL_GLM, dat, as_vector=F)
init=list(m=get_skeleton(sampler), s=get_skeleton(sampler))
init$m$conc=log(o$par$conc)
init$m$beta=o$par$beta
for (n in names(init$s)) init$s[[n]][]=1 # set all standard deviations to 1 initially
for (n in names(init)) init[[n]]=unlist(init[[n]])
# set the seed so we can use the same seed for the alternative model
set.seed(1)
null_gradient_function=function(g) sampler$grad_log_prob(g,T)
null_likelihood=function(g) sampler$log_prob(g,T,F)
v_null=svem(null_gradient_function, to_optim, init, plot.elbo = F, iterations = iterations, samples_for_elbo = 0, log_prob = null_likelihood)
# data for alternative (full) model
dat_full=list(N=length(ys), P=ncol(xFull), K=max(z), ys=ys,ns=ns,x=xFull, z=z, concShape=concShape, concRate=concRate)
# specify which parameters to optimize
sampler2=get_sampler(BETABINOMIAL_GLMM, dat_full)
sk_full=get_skeleton(sampler2)
sk_full$conc=T
sk_full$logrev=T
sk_full$beta[]=T
sk_full$u[]=F
to_optim=as.logical(unlist(sk_full))
# initialization choices: initializing from null fit seems best
if (0) {
o_init=o$par
o_init$beta=c(o_init$beta, rep(0,df))
o=optimizing(STANGLM_MV, dat_full, as_vector=F)
init=list(m=get_skeleton(sampler2), s=get_skeleton(sampler2))
init$m$conc=log(o$par$conc)
init$m$beta=o$par$beta
for (n in names(init$s)) init$s[[n]][]=1
} else {
init=list( m=rstan:::rstan_relist(v_null$m, sk),
s=rstan:::rstan_relist(v_null$s, sk) )
init$m$beta=c(init$m$beta, rep(0,df))
init$s$beta=c(init$s$beta, rep(1,df)) # optimized anyway so this value will be ignored
}
init=list(m=unlist(init$m),s=unlist(init$s))
# fit alternative model
set.seed(1)
v_full=svem(function(g) sampler2$grad_log_prob(g,T), to_optim, init=init, plot.elbo = F, iterations = iterations, samples_for_elbo = 0, function(g) sampler2$log_prob(g,T,F))
# using the same random draws to estimate the deviance is more efficient
nintegrate=sum(!to_optim)
loglr=mean(sapply(1:elbo_samples, function(g) {
x=rnorm(nintegrate)
v_full$elbo_func( x ) - v_null$elbo_func( x ) }))
#loglr=mean(v_full$elbo_progress[(maxit/2):maxit] - v_null$elbo_progress[(maxit/2):maxit])
list(loglr=loglr, df=df, lrtp=pchisq( 2.0*loglr, lower.tail = F , df=df ) )
betaBinomialGLMM=function(ys,ns,xFull,xNull,z,concShape=1.0001,concRate=1e-4,iterations=5000,elbo_samples=3000,...) {
# check first ncol(xNull) columns of xFull and xNull match
stopifnot(all(xNull==xFull[,1:ncol(xNull)]))
# degress of freedom
df=ncol(xFull)-ncol(xNull)
# data for the null model
dat=list(N=length(ys), P=ncol(xNull), K=max(z), ys=ys,ns=ns,x=xNull,z=z, concShape=concShape, concRate=concRate)
# get stan_fit object so we can call sampler$grad_log_prob for the gradient
sampler=get_sampler(BETABINOMIAL_GLMM, dat)
# specific which parameters to optimize (rather than integrate over)
sk=get_skeleton(sampler)
sk$conc=T
sk$logrev=T
sk$beta[]=T
sk$u[]=F
to_optim=as.logical(unlist(sk))
# we initialize using the model fit without the random effects
o=optimizing(BETABINOMIAL_GLM, dat, as_vector=F)
init=list(m=get_skeleton(sampler), s=get_skeleton(sampler))
init$m$conc=log(o$par$conc)
init$m$beta=o$par$beta
for (n in names(init$s)) init$s[[n]][]=1 # set all standard deviations to 1 initially
for (n in names(init)) init[[n]]=unlist(init[[n]])
# set the seed so we can use the same seed for the alternative model
set.seed(1)
null_gradient_function=function(g) sampler$grad_log_prob(g,T)
null_likelihood=function(g) sampler$log_prob(g,T,F)
v_null=svem(null_gradient_function, to_optim, init, plot.elbo = F, iterations = iterations, samples_for_elbo = 0, log_prob = null_likelihood)
# data for alternative (full) model
dat_full=list(N=length(ys), P=ncol(xFull), K=max(z), ys=ys,ns=ns,x=xFull, z=z, concShape=concShape, concRate=concRate)
# specify which parameters to optimize
sampler2=get_sampler(BETABINOMIAL_GLMM, dat_full)
sk_full=get_skeleton(sampler2)
sk_full$conc=T
sk_full$logrev=T
sk_full$beta[]=T
sk_full$u[]=F
to_optim=as.logical(unlist(sk_full))
# initialization choices: initializing from null fit seems best
if (0) {
o_init=o$par
o_init$beta=c(o_init$beta, rep(0,df))
o=optimizing(STANGLM_MV, dat_full, as_vector=F)
init=list(m=get_skeleton(sampler2), s=get_skeleton(sampler2))
init$m$conc=log(o$par$conc)
init$m$beta=o$par$beta
for (n in names(init$s)) init$s[[n]][]=1
} else {
init=list( m=rstan:::rstan_relist(v_null$m, sk),
s=rstan:::rstan_relist(v_null$s, sk) )
init$m$beta=c(init$m$beta, rep(0,df))
init$s$beta=c(init$s$beta, rep(1,df)) # optimized anyway so this value will be ignored
}
init=list(m=unlist(init$m),s=unlist(init$s))
# fit alternative model
set.seed(1)
v_full=svem(function(g) sampler2$grad_log_prob(g,T), to_optim, init=init, plot.elbo = F, iterations = iterations, samples_for_elbo = 0, function(g) sampler2$log_prob(g,T,F))
# using the same random draws to estimate the deviance is more efficient
nintegrate=sum(!to_optim)
loglr=mean(sapply(1:elbo_samples, function(g) {
x=rnorm(nintegrate)
v_full$elbo_func( x ) - v_null$elbo_func( x ) }))
#loglr=mean(v_full$elbo_progress[(maxit/2):maxit] - v_null$elbo_progress[(maxit/2):maxit])
list(loglr=loglr, df=df, lrtp=pchisq( 2.0*loglr, lower.tail = F , df=df ) )
}
testbbglmm=function(seed=1) {
set.seed(seed)
nsamp=50
ns=rpois(nsamp * 2,lambda=10)
ys=rbinom(nsamp * 2,ns,logistic(.3+.3*rnorm(nsamp)))
xNull=cbind(numeric(nsamp*2)+1)
xFull=cbind(xNull,c(rep(0,nsamp),rep(1,nsamp)))
z=rep(1:nsamp,2)
c(betaBinomialGLMM(ys,ns,xFull,xNull,z)$lrtp, betaBinomialGLM(ys,ns,xFull,xNull)$lrtp[1])
}
a=foreach(i=1:100) %dopar% { testbbglmm(i) }
pv=do.call(rbind,a)
qplot(pv[,2],pv[,1]) + geom_abline(intercept=0,slope=1) + xlab("GLM -log10(p)") + ylab("GLMM -log10(p)") + theme_bw(base_size=16)
hist(pv[,1])
hist(pv[,2])
hist(pv[,1])
results=foreach(i=1:14) %dopar% {
set.seed(i)
res=.3 # random effect standard deviation
fe=.5
nsamp=50
ns=rpois(nsamp * 2,lambda=30)
z=rep(1:nsamp,2)
u=rnorm(nsamp)
x=c(rep(0,nsamp),rep(1,nsamp))
ys=rbinom(nsamp * 2,ns,logistic(.3+.3*rnorm(2*nsamp)+res*u[z]+fe*x))
xNull=cbind(numeric(nsamp*2)+1)
xFull=cbind(xNull,x)
c(betaBinomialGLMM(ys,ns,xFull,xNull,z)$lrtp, betaBinomialGLM(ys,ns,xFull,xNull)$lrtp[1])
}
pvals=as.data.frame(do.call(rbind,results))
colnames(pvals)=c("GLMM","GLM")
qplot(-log10(pvals$GLM),-log10(pvals$GLMM))+geom_abline(intercept=0,slope=1)+theme_bw(base_size = 16)
source("betabinomial_glmm.R")
source("betabinomial_glmm.R")
set.seed(i)
res=.3 # random effect standard deviation
fe=.5
nsamp=50
ns=rpois(nsamp * 2,lambda=30)
z=rep(1:nsamp,2)
u=rnorm(nsamp)
x=c(rep(0,nsamp),rep(1,nsamp))
ys=rbinom(nsamp * 2,ns,logistic(.3+.3*rnorm(2*nsamp)+res*u[z]+fe*x))
xNull=cbind(numeric(nsamp*2)+1)
xFull=cbind(xNull,x)
c(betaBinomialGLMM(ys,ns,xFull,xNull,z)$lrtp, betaBinomialGLM(ys,ns,xFull,xNull)$lrtp[1])
testbbglmm=function(seed=1,random_effect_sd=.3, fixed_effect=.5,nsamp=50,av_counts=30) {
set.seed(seed)
ns=rpois(nsamp * 2,lambda=av_counts)
z=rep(1:nsamp,2)
u=rnorm(nsamp)
x=c(rep(0,nsamp),rep(1,nsamp))
ys=rbinom(nsamp * 2,ns,logistic(.3+.3*rnorm(2*nsamp)+random_effect_sd*u[z]+fe*x))
xNull=cbind(numeric(nsamp*2)+1)
xFull=cbind(xNull,x)
c(betaBinomialGLMM(ys,ns,xFull,xNull,z)$lrtp, betaBinomialGLM(ys,ns,xFull,xNull)$lrtp[1])
}
testbbglmm
testbbglmm()
testbbglmm(fixed_effect = 0)
testbbglmm=function(seed=1,random_effect_sd=.3, fixed_effect=.5,nsamp=50,av_counts=30) {
set.seed(seed)
ns=rpois(nsamp * 2,lambda=av_counts)
z=rep(1:nsamp,2)
u=rnorm(nsamp)
x=c(rep(0,nsamp),rep(1,nsamp))
ys=rbinom(nsamp * 2,ns,logistic(.3+.3*rnorm(2*nsamp)+random_effect_sd*u[z]+fixed_effect*x))
xNull=cbind(numeric(nsamp*2)+1)
xFull=cbind(xNull,x)
c(betaBinomialGLMM(ys,ns,xFull,xNull,z)$lrtp, betaBinomialGLM(ys,ns,xFull,xNull)$lrtp[1])
}
testbbglmm(fixed_effect = 0)
under_null=foreach(i=1:100) %dopar% { testbbglmm(seed=i, fixed_effect=0) }
pv=do.call(rbind,under_null)
qplot(pv[,2],pv[,1]) + geom_abline(intercept=0,slope=1) + xlab("GLM -log10(p)") + ylab("GLMM -log10(p)") + theme_bw(base_size=16)
under_full=foreach(i=1:100) %dopar% { testbbglmm(seed=i, fixed_effect=.5) }
pvals=as.data.frame(do.call(rbind,results))
colnames(pvals)=c("GLMM","GLM")
qplot(-log10(pvals$GLM),-log10(pvals$GLMM))+geom_abline(intercept=0,slope=1)+theme_bw(base_size = 16)
pvals=as.data.frame(do.call(under_full))
colnames(pvals)=c("GLMM","GLM")
qplot(-log10(pvals$GLM),-log10(pvals$GLMM))+geom_abline(intercept=0,slope=1)+theme_bw(base_size = 16)
pvals=as.data.frame(do.call(rbind,under_full))
colnames(pvals)=c("GLMM","GLM")
qplot(-log10(pvals$GLM),-log10(pvals$GLMM))+geom_abline(intercept=0,slope=1)+theme_bw(base_size = 16)
qplot(-log10(pvals$GLM),-log10(pvals$GLMM))+geom_abline(intercept=0,slope=1)+theme_bw(base_size = 16)+ xlab("GLM -log10(p)") + ylab("GLMM -log10(p)")
qplot(pv[,2],pv[,1]) + geom_abline(intercept=0,slope=1) + xlab("GLM -log10(p)") + ylab("GLMM -log10(p)") + theme_bw(base_size=16)
hist(pv[,1])
hist(pv[,2])
hist(pv[,1])
hist(pv[,2])
source('~/Dropbox/rocke_experiments/stan_models/betabinomial_glm.R', echo=TRUE)
source('~/Dropbox/rocke_experiments/stan_models/betabinomial_glm.R', echo=TRUE)
testbbglm()
source('~/Dropbox/rocke_experiments/stan_models/betabinomial_glm.R', echo=TRUE)
testbbglm()
nsamp=100
ns=rpois(nsamp,lambda=10)
ys=rbinom(nsamp,ns,logistic(.3+.3*rnorm(nsamp)))
xNull=cbind(numeric(nsamp)+1)
xFull=cbind(xNull,runif(nsamp))
anova_result=betaBinomialGLM(ys,ns,xFull,xNull)
get_glm_coefs(anova_result$betaNull)
get_glm_coefs=function(res) {
p=length(res$par$beta)
variance=robustSolve(-res$hessian)
dimnames(variance)=dimnames(res$hessian)
betase=sqrt(diag(variance))[paste0("beta.",1:p)]
beta=res$par[paste0("beta[",1:p,"]")]
zscore=res$par$beta / betase
data.frame(co=res$par$beta,se=betase,p=2.0*pnorm(-abs(zscore)))
}
get_glm_coefs(anova_result$betaNull)
get_glm_coefs=function(res) {
p=length(res$par$beta)
variance=robustSolve(-res$hessian)
dimnames(variance)=dimnames(res$hessian)
betase=sqrt(diag(variance))[paste0("beta.",1:p)]
beta=res$par[paste0("beta[",1:p,"]")]
zscore=res$par$beta / betase
data.frame(co=res$par$beta,se=betase,p=2.0*pnorm(-abs(zscore)))
}
get_glm_coefs(anova_result$betaNull)
get_glm_coefs(anova_result$fit_null)
source('~/.active-rstudio-document', echo=TRUE)
nsamp=100
ns=rpois(nsamp,lambda=10)
ys=rbinom(nsamp,ns,logistic(.3+.3*rnorm(nsamp)))
xNull=cbind(numeric(nsamp)+1)
xFull=cbind(xNull,runif(nsamp))
anova_result=betaBinomialGLM(ys,ns,xFull,xNull)
get_glm_coefs(anova_result$fit_null)
get_glm_coefs(anova_result$fit_full)
source("betabinomial_glm.R")
source('~/.active-rstudio-document', echo=TRUE)
source('~/Dropbox/rocke_experiments/stan_models/test_bb_glmm.R', echo=TRUE)
qplot(pv[,2],pv[,1]) + geom_abline(intercept=0,slope=1) + xlab("GLM -log10(p)") + ylab("GLMM -log10(p)") + theme_bw(base_size=16)
qplot(-log10(pvals$GLM),-log10(pvals$GLMM))+geom_abline(intercept=0,slope=1)+theme_bw(base_size = 16)+ xlab("GLM -log10(p)") + ylab("GLMM -log10(p)")
qplot(pv[,2],pv[,1]) + geom_abline(intercept=0,slope=1) + xlab("GLM -log10(p)") + ylab("GLMM -log10(p)") + theme_bw(base_size=16)
pv=-log10(do.call(rbind,under_null))
qplot(pv[,2],pv[,1]) + geom_abline(intercept=0,slope=1) + xlab("GLM -log10(p)") + ylab("GLMM -log10(p)") + theme_bw(base_size=16)
pqplot(pv[,1])
pv=do.call(rbind,under_null)
pqplot(pv[,1])
pqplot(pv[,2])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
pqplot(pv[,1])
under_null=foreach(i=1:100) %dopar% { testbbglmm(seed=i, fixed_effect=0) }
pv=do.call(rbind,under_null)
qplot(pv[,2],pv[,1]) + geom_abline(intercept=0,slope=1) + xlab("GLM -log10(p)") + ylab("GLMM -log10(p)") + theme_bw(base_size=16)
pqplot(pv[,1])
pqplot(pv[,2])
pqplot(pv[,2])
qplot(-log10(pvals$GLM),-log10(pvals$GLMM))+geom_abline(intercept=0,slope=1)+theme_bw(base_size = 16)+ xlab("GLM -log10(p)") + ylab("GLMM -log10(p)")
source('~/Dropbox/rocke_experiments/beta_binomial_models/test_bb_glmm.R', echo=TRUE)
setwd("~/Dropbox/rocke_experiments/beta_binomial_models")
source('~/Dropbox/rocke_experiments/beta_binomial_models/test_bb_glmm.R', echo=TRUE)
